{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lmdb\n",
    "import json\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from transformers import AutoProcessor, Pix2StructForConditionalGeneration\n",
    "from utils import round_float, is_nan\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_TOKEN = \"<|BOS|>\"\n",
    "X_START = \"<|x_start|>\"\n",
    "X_END = \"<|x_end|>\"\n",
    "Y_START = \"<|y_start|>\"\n",
    "Y_END = \"<|y_end|>\"\n",
    "\n",
    "\n",
    "SEPARATOR_TOKENS = [\n",
    "    BOS_TOKEN,\n",
    "    X_START,\n",
    "    X_END,\n",
    "    Y_START,\n",
    "    Y_END,\n",
    "]\n",
    "\n",
    "LINE_TOKEN = \"<line>\"\n",
    "VERTICAL_BAR_TOKEN = \"<vertical_bar>\"\n",
    "HORIZONTAL_BAR_TOKEN = \"<horizontal_bar>\"\n",
    "SCATTER_TOKEN = \"<scatter>\"\n",
    "DOT_TOKEN = \"<dot>\"\n",
    "\n",
    "CHART_TYPE_TOKENS = [\n",
    "    LINE_TOKEN,\n",
    "    VERTICAL_BAR_TOKEN,\n",
    "    HORIZONTAL_BAR_TOKEN,\n",
    "    SCATTER_TOKEN,\n",
    "    DOT_TOKEN,\n",
    "]\n",
    "\n",
    "new_tokens = SEPARATOR_TOKENS + CHART_TYPE_TOKENS\n",
    "\n",
    "max_patches = 1024\n",
    "max_length = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained('../../../outputs/6_17')\n",
    "processor.image_processor.size = {\n",
    "    \"height\": 560,\n",
    "    \"width\": 560,\n",
    "}\n",
    "processor.image_processor.is_vqa = False\n",
    "processor.tokenizer.add_tokens(new_tokens)\n",
    "\n",
    "model = Pix2StructForConditionalGeneration.from_pretrained('../../../outputs/6_17')\n",
    "model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
    "model.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids([BOS_TOKEN])[0]\n",
    "model.config.text_config.is_decoder = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('../../../outputs/6_17')\n",
    "processor.save_pretrained('../../../outputs/6_17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = lmdb.open('../../../data/data0004/lmdb', max_readers=32,\n",
    "#                 readonly=True, lock=False, readahead=False, meminit=False)\n",
    "# with env.begin(write=False) as txn:\n",
    "#     n_samples = int(txn.get('num-samples'.encode()))\n",
    "#     for idx in trange(n_samples):\n",
    "#         # load json\n",
    "#         label_key = f'label-{str(idx+1).zfill(8)}'.encode()\n",
    "#         label = txn.get(label_key).decode('utf-8')\n",
    "#         json_dict = json.loads(label)\n",
    "#         data_str = data_series_to_string(json_dict)\n",
    "#         token_ids = processor.tokenizer.encode(data_str)\n",
    "#         tokens = processor.tokenizer.tokenize(data_str)\n",
    "#         for token, token_id in zip(tokens, token_ids):\n",
    "#             if token_id == unk_token_id:\n",
    "#                 unk_tokens.append(token)\n",
    "#     unk_counter = Counter(unk_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MgaDataset(Dataset):\n",
    "    def __init__(self, lmdb_dir, processor):\n",
    "        self.processor = processor\n",
    "        self.env = lmdb.open(str(lmdb_dir), max_readers=32,\n",
    "                             readonly=True, lock=False, readahead=False, meminit=False)\n",
    "\n",
    "    def _json_dict_to_gt_string(self, json_dict) -> str:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_dict (Dict[str, Any]): ターゲットのdict\n",
    "        Returns:\n",
    "            gt_string (str): 入力となるプロンプト\n",
    "        \"\"\"\n",
    "        all_x, all_y = [], []\n",
    "\n",
    "        for d in json_dict['data-series']:\n",
    "            x = d[\"x\"]\n",
    "            y = d[\"y\"]\n",
    "\n",
    "            x = round_float(x)\n",
    "            y = round_float(y)\n",
    "\n",
    "            # Ignore nan values\n",
    "            if is_nan(x) or is_nan(y):\n",
    "                continue\n",
    "\n",
    "            all_x.append(x)\n",
    "            all_y.append(y)\n",
    "\n",
    "        chart_type = f\"<{json_dict['chart-type']}>\"\n",
    "        x_str = X_START + \";\".join(list(map(str, all_x))) + X_END\n",
    "        y_str = Y_START + \";\".join(list(map(str, all_y))) + Y_END\n",
    "\n",
    "        gt_string = BOS_TOKEN + chart_type + x_str + y_str\n",
    "\n",
    "        return gt_string, list(map(str, all_x)), list(map(str, all_y))\n",
    "\n",
    "    def __len__(self):\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            n_samples = txn.get('num-samples'.encode())\n",
    "        return n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        lmdbからidに一致したimageとlabelを取り出す\n",
    "\n",
    "        image\n",
    "            - byteをdecodeしてPIL.Image -> numpyにする\n",
    "\n",
    "        label\n",
    "            - byteからjson.loadsでdictにする\n",
    "                keys: ['source', 'chart-type', 'plot-bb', 'text',\n",
    "                    'axes', 'data-series', 'id', 'key_point']\n",
    "            - 'data-series'から正解となるpromptを生成\n",
    "\n",
    "        Returns:\n",
    "            samples (Dict[str, Union[torch.Tensor, List[int], str]])\n",
    "                pixel_values (torch.Tensor): 画像\n",
    "                input_ids (List[int]): token idのリスト\n",
    "                ids (str)\n",
    "        \"\"\"\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            # load image\n",
    "            img_key = f'image-{str(idx+1).zfill(8)}'.encode()\n",
    "            imgbuf = txn.get(img_key)\n",
    "\n",
    "            # load json\n",
    "            label_key = f'label-{str(idx+1).zfill(8)}'.encode()\n",
    "            label = txn.get(label_key).decode('utf-8')\n",
    "\n",
    "        # label: ['source', 'chart-type', 'plot-bb', 'text', 'axes', 'data-series', 'id', 'key_point']\n",
    "        json_dict = json.loads(label)\n",
    "\n",
    "        # image\n",
    "        buf = six.BytesIO()\n",
    "        buf.write(imgbuf)\n",
    "        buf.seek(0)\n",
    "        image_arr = np.array(Image.open(buf).convert('RGB'))\n",
    "        h, w, _ = image_arr.shape\n",
    "        encoding = processor(\n",
    "            images=image_arr,\n",
    "            random_padding=True,\n",
    "            add_special_tokens=True,\n",
    "            max_patches=max_patches,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        # encoding = {k: v[0].squeeze() for k, v in encoding.items()}\n",
    "        # encoding = {k: v for k, v in encoding.items()}\n",
    "\n",
    "        gt_string, _, _ = self._json_dict_to_gt_string(json_dict)\n",
    "\n",
    "        text_inputs = processor(\n",
    "            text=gt_string,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length\n",
    "        ).input_ids\n",
    "\n",
    "        encoding['labels'] = text_inputs\n",
    "        encoding['source'] = 0 if json_dict['source'] == 'generaeted' else 1\n",
    "        encoding['id'] = json_dict['id']\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MgaDataset('../../../data/data0004/lmdb', processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.__getitem__(0)\n",
    "labels = data['labels']\n",
    "output = model(\n",
    "    flattened_patches=data['flattened_patches'], #.unsqueeze(0),\n",
    "    attention_mask=data['attention_mask'], # .unsqueeze(0)\n",
    "    labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 50354])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50344, 50352, 50345,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|x_start|>'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(labels[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(output.logits.reshape(-1, model.decoder.config.vocab_size), labels.reshape(-1))\n",
    "chart_type_loss = loss_fn(output.logits.reshape(-1, model.decoder.config.vocab_size)[1:2, :], labels.reshape(-1)[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 50354])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.reshape(-1, model.decoder.config.vocab_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6274, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart_type_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|BOS|><scatter><|x_start|> 1.0'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(labels.reshape(-1)[0:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 50354])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, extracted_weight=100.):\n",
    "        super().__init__()\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        self.extracted_weight = extracted_weight\n",
    "    \n",
    "    def forward(self, input, target, source):\n",
    "        '''\n",
    "            input: (bs, length, vocab_size)\n",
    "            target: (bs, length)\n",
    "            source: (bs)\n",
    "        '''\n",
    "\n",
    "        bs, l, vs = input.shape\n",
    "        input = input.reshape(-1, vs)\n",
    "        target = target.reshape(-1)\n",
    "        source = torch.tile(source, (1, l)).reshape(-1)\n",
    "        weight = self.extracted_weight * source + (1. - source)\n",
    "\n",
    "        ls = self.log_softmax(input)\n",
    "        loss_per_bs = -1 * ls.index_select(-1, target).diag() # (bs * len)\n",
    "        return torch.mean(loss_per_bs * weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred: (bs, len, voc_size)\n",
    "# target: (bs, len)\n",
    "\n",
    "# source: (bs, ) => (bs, len)\n",
    "\n",
    "# loss_input: (bs * len, voc_size)\n",
    "# loss_target: (bs * len)\n",
    "\n",
    "# loss_per_bs: (bs)\n",
    "\n",
    "# bs = 2, len=3, voc_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.randn((2, 3, 4)).float()\n",
    "target = torch.tensor([\n",
    "    [1, 0, 2],\n",
    "    [0, 0, 3]\n",
    "]).long()\n",
    "source = torch.tensor([1, 1]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce loss tensor(1.5734)\n",
      "custom loss tensor(157.3420)\n"
     ]
    }
   ],
   "source": [
    "# pred = torch.tensor([[-100, -0.2, 0.5], [0.8, -0.2, 0.5]]).float()\n",
    "# target = torch.tensor([0, 2]).long()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "print('ce loss', loss_fn(pred.reshape(-1, 4), target.reshape(-1)))\n",
    "custom_loss_fn = CustomLoss()\n",
    "print('custom loss', custom_loss_fn(pred, target, source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7461)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7461])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7632, -2.1829, -0.8648],\n",
       "        [-1.5033, -1.8776, -0.4706]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.randn(2, 3)\n",
    "s(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(np.arange(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 41, 25, 30, 24, 14, 37, 60, 71, 78]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mga-RYrVM4UM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
